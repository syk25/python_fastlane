{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a href='https://cafe.naver.com/jmhonglab'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
    "___\n",
    "<center><em>Content Copyright by HongLab, Inc.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배경 교체"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 녹색 배경으로 촬영된 영상\n",
    "\n",
    "1. 배경으로 사용할 이미지를 읽어들여서 동영상과 같은 해상도로 [cv::resize()](https://docs.opencv.org/4.x/da/d54/group__imgproc__transform.html#ga47a974309e9102f5f08231edc7e7529d)\n",
    "2. [cv::inRange()](https://docs.opencv.org/3.4/d2/de8/group__core__array.html#ga48af0ab51e36436c5d04340e036ce981)를 이용해서 mask 만들기\n",
    "3. [옵션] ```GaussianBlur()```를 이용해서 mask를 더 부드럽게 만들기\n",
    "4. 알파 블랜딩과 비슷하게 ```mask```를 이용해서 동영상과 배경 합성\n",
    "\n",
    "```\n",
    "mask = cv2.inRange(frame, (15, 142, 88), (55, 215, 150))\n",
    "```\n",
    "\n",
    "frame의 필셀들 중에서 $15 \\leq B \\leq 55$, $142 \\leq G \\leq 215$, $88 \\leq R \\leq 150$를 모두 만족하는 픽셀의 위치에 해당하는 mask는 255, 그 외에는 0\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "mask = cv2.GaussianBlur(mask, (15, 15), 0)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(\"green_background.mp4\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening video  file\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "background = cv2.imread(\"point_fermin_park.jpg\")\n",
    "background = cv2.resize(background, (int(width), int(height)))\n",
    "background = cv2.GaussianBlur(background, (25, 25), 0)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"X264\")\n",
    "out = cv2.VideoWriter(\"without_gaussian.mp4\", fourcc, fps, (int(width), int(height)))\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"End of frames.\")\n",
    "        break\n",
    "\n",
    "    # 녹색과 비슷하면 255, 아니면 0\n",
    "    mask = cv2.inRange(frame, (15, 142, 88), (55, 215, 150))\n",
    "    mask = cv2.GaussianBlur(mask, (15, 15), 0)\n",
    "    # cv2.imwrite(\"mask_blur.jpg\", mask)\n",
    "    # cv2.waitKey(0)\n",
    "    # break\n",
    "    mask = np.expand_dims(mask, 2) / 255.0\n",
    "\n",
    "    comp = frame * (1.0 - mask) + background * mask\n",
    "    comp = comp.astype(np.uint8)\n",
    "\n",
    "    out.write(comp)\n",
    "    cv2.imshow(\"Comp\", comp)\n",
    "\n",
    "    if cv2.waitKey(int(100.0 / fps)) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임의의 배경 교체 (딥러닝)\n",
    "\n",
    "[MediaPipe](https://google.github.io/mediapipe/)의 [Selfie Segmentation](https://google.github.io/mediapipe/solutions/selfie_segmentation#mediapipe-selfie-segmentation) 사용\n",
    "\n",
    "```\n",
    "pip install mediapipe\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기초적인 사용 방법\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "with mp.solutions.selfie_segmentation.SelfieSegmentation(\n",
    "    model_selection=1\n",
    ") as selfie_segmentation:\n",
    "\n",
    "    image = cv2.imread(\"arbitrary_background.jpg\")\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # for neural network\n",
    "\n",
    "    # 백그라운드가 1.0이 되도록 수정\n",
    "    mask = 1.0 - selfie_segmentation.process(image).segmentation_mask\n",
    "\n",
    "cv2.imwrite(\"mediapipe_mask.jpg\", mask * 255.0)\n",
    "# cv2.imshow(\"Mask\", mask)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8018e705143a54fe8977c076a25f32bbbfeba551799f40fa3d5ac4e2da245feb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
