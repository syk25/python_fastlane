{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a href='https://cafe.naver.com/jmhonglab'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
    "___\n",
    "<center><em>Content Copyright by HongLab, Inc.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이썬 음성 인식 (Speech Recognition)\n",
    "\n",
    "컴퓨터에 연결된 마이크가 필요합니다. 화상회의 용으로 사용하는 노트북 내장 마이크나 헤드셋 내장 마이크 등이면 충분합니다. 스마트폰용으로 나온 마이크 달린 이어폰을 PC에 연결할 경우에는 연결 단자의 종류가 달라서 마이크가 작동하지 않을 수도 있으니 주의하세요.\n",
    "\n",
    "### 음성 인식의 원리 요약\n",
    "\n",
    "마이크로 입력받은 음성 신호를 분석하기에 좋은 디지털 오디오 데이터로 변환한 후에 기계학습으로 훈련된 모델을 이용하여 문자열로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 패키지들 설치\n",
    "\n",
    "- [SpeechRecognition](https://github.com/Uberi/speech_recognition#readme)\n",
    "- [PyAudio](http://people.csail.mit.edu/hubert/pyaudio/): 마이크와 스피커를 통한 오디오 입력과 출력\n",
    "\n",
    "윈도우 운영체제에서는 아래와 같이 비교적 쉽게 설치할 수 있습니다.  \n",
    "(미니콘다 파이썬 3.10.0 가상환경 기준)\n",
    "```\n",
    "pip install SpeechRecognition\n",
    "pip install pipwin\n",
    "pipwin install pyaudio\n",
    "```\n",
    "맥에서 PyAudio를 설치하는 방법은 따로 안내해드리겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 음성 인식기 사용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 내 컴퓨터에 마이크가 설치되어 있는지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['세연의 AirPods Pro',\n",
       " '세연의 AirPods Pro',\n",
       " 'BlackHole 2ch',\n",
       " 'MacBook Air Microphone',\n",
       " 'MacBook Air Speakers',\n",
       " \"sy's iphone Microphone\",\n",
       " 'Multi-Output Device',\n",
       " 'Multi-Output Device']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# speech_recognition 버전 체크\n",
    "print(sr.__version__)\n",
    "\n",
    "# 가지고 있는 마이크 목록 확인\n",
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 음성 인식을 할 수 있습니다. 여기서는 구글 온라인 인식기를 사용하였습니다. 인터넷이 연결되어 있어야 하며 [사용량에 제한](https://cloud.google.com/speech-to-text/quotas#:~:text=for%20more%20information.-,Content%20Limits,the%20API%20using%20local%20files)이 있을 수도 있습니다. 더 다양한 인식기를 사용하는 예제는 [여기서](https://github.com/Uberi/speech_recognition/blob/master/examples/microphone_recognition.py) 보실 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음성 인식 대기중\n",
      "인식 결과: 안녕하세요\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# 인식기(Recognizer) 객체를 만듭니다.\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# 마이크 객체를 만듭니다. \n",
    "microphone = sr.Microphone() # 대부분의 경우 device_index 생략 가능합니다.\n",
    "\n",
    "# 마이크로 음성을 녹음합니다.\n",
    "# with microphone as source는 microphone 객체를 사용할 준비를 시키고 \n",
    "# with-블럭 안에서 source라는 이름으로 사용하겠다는 의미입니다.\n",
    "# 어떤 자료형의 객체가 with문과 같이 사용될 수 있는지 아닌지는 \n",
    "# 미리 정해져 있기 때문에 보통 예제 코드를 참고해서 사용합니다.\n",
    "with microphone as source:\n",
    "    r.adjust_for_ambient_noise(source) # 배경 소음을 측정합니다.\n",
    "    print(\"음성 인식 대기중\")\n",
    "    audio = r.listen(source) # 일정 크기 이상의 소리가 들리면 녹음합니다.\n",
    "\n",
    "# with-as 블럭 안에서 정의한 변수인 audio를 블럭 밖에서도 사용할 수 있습니다.\n",
    "text = r.recognize_google(audio, language=\"ko\")\n",
    "\n",
    "print(\"인식 결과:\", text)\n",
    "\n",
    "# 음성을 제대로 인식하지 못하는 경우도 시연"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "microphone = sr.Microphone(device_index=2)\n",
    "\n",
    "with microphone as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    print(\"음성 인식 대기중\")\n",
    "    audio = r.listen(source)\n",
    "\n",
    "text = r.recognize_google(audio, language=\"ko\")\n",
    "\n",
    "print(\"인식 결과:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음성 인식 대기중\n",
      "인식 결과: 안녕하세요\n",
      "음성 인식 대기중\n",
      "인식 결과: 반갑습니다\n",
      "음성 인식 대기중\n",
      "인식 결과: 인식을 하는데 시간이 좀 걸리네요\n",
      "음성 인식 대기중\n",
      "인식 결과: 말 잘 알아 들으시오\n",
      "음성 인식 대기중\n",
      "인식 결과: 꼴깍 꼴깍 꼴깍 꼴깍\n",
      "음성 인식 대기중\n"
     ]
    },
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m음성 인식 대기중\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     audio \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mlisten(source)\n\u001b[0;32m---> 14\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mko\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m인식 결과:\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fast_lane/lib/python3.10/site-packages/speech_recognition/recognizers/google.py:263\u001b[0m, in \u001b[0;36mrecognize_legacy\u001b[0;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[1;32m    256\u001b[0m response_text \u001b[38;5;241m=\u001b[39m obtain_transcription(\n\u001b[1;32m    257\u001b[0m     request, timeout\u001b[38;5;241m=\u001b[39mrecognizer\u001b[38;5;241m.\u001b[39moperation_timeout\n\u001b[1;32m    258\u001b[0m )\n\u001b[1;32m    260\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m OutputParser(\n\u001b[1;32m    261\u001b[0m     show_all\u001b[38;5;241m=\u001b[39mshow_all, with_confidence\u001b[38;5;241m=\u001b[39mwith_confidence\n\u001b[1;32m    262\u001b[0m )\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fast_lane/lib/python3.10/site-packages/speech_recognition/recognizers/google.py:134\u001b[0m, in \u001b[0;36mOutputParser.parse\u001b[0;34m(self, response_text)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, response_text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 134\u001b[0m     actual_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_all:\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m actual_result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fast_lane/lib/python3.10/site-packages/speech_recognition/recognizers/google.py:183\u001b[0m, in \u001b[0;36mOutputParser.convert_to_result\u001b[0;34m(response_text)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n",
      "\u001b[0;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "microphone = sr.Microphone()\n",
    "\n",
    "while True:\n",
    "\n",
    "    with microphone as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        print(\"음성 인식 대기중\")\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    text = r.recognize_google(audio, language=\"ko\")\n",
    "    print(\"인식 결과:\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```raise UnknownValueError()``` 같은 예외 상황을 처리하기 위해 ```try-except-else```를 사용해보겠습니다.\n",
    "\n",
    "\n",
    "```try-except-else```는 프로그래머 입장에서 예측하기 어려운 예외적인 상황을 처리할 때 사용합니다. 주로 파일처리나 인터넷 연결과 같이 하드웨어와 관련된 상황에서 사용합니다. ```except```문은 예외의 종류에 따라 여러번 사용할 수도 있습니다. 예외의 종류에 대해서는 미리 정해져있기 때문에 대부분의 경우 예제 코드를 참고해서 구현합니다.\n",
    "\n",
    "```\n",
    "try:\n",
    "    일단 실행해볼 명령문 블럭\n",
    "except:\n",
    "    예외적인 상황이 발생했을 때 실행할 명령문 블럭\n",
    "else:\n",
    "    예외가 발생하지 않았을 때 실행할 명령문 블럭\n",
    "finally:\n",
    "    예외 발생과 상관 없이 실행할 명령문 블럭\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "microphone = sr.Microphone()\n",
    "\n",
    "while True:\n",
    "\n",
    "    with microphone as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        print(\"음성 인식 대기중\")\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    # 음성을 인식합니다.\n",
    "    # try-except-else 사용\n",
    "    try:\n",
    "        # 구글 인식기를 이용하여 음성을 문자열로 바꿉니다.\n",
    "        # 언어도 선택할 수 있습니다. 영어는 \"en\"\n",
    "        text = r.recognize_google(audio, language=\"ko\")\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"인식할 수 없습니다.\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"인식에 문제가 있습니다.\", e)\n",
    "    else:\n",
    "        print(\"인식 결과:\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [실습] '종료'라고 얘기하면 종료가 되도록 기능을 추가해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음성 인식 대기중\n",
      "인식 결과: 안녕\n",
      "음성 인식 대기중\n",
      "종료하였습니다.\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "microphone = sr.Microphone()\n",
    "\n",
    "# 여기에 구현\n",
    "\"\"\" \n",
    "음성인식 1. 배경소음 측정 2. 듣기 3. 변환하기 \"\"\"\n",
    "while True:\n",
    "    with microphone as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        print(\"음성 인식 대기중\")\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    try:\n",
    "        text = r.recognize_google(audio, language=\"ko\")\n",
    "        if text == \"종료\":\n",
    "            print(\"종료하였습니다.\")\n",
    "            break\n",
    "        print(\"인식 결과:\", text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"인식할 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고] ```r.reconrd()```를 이용해서 정해진 시간 동안 녹음을 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앞으로 5초 동안 녹음합니다.\n",
      "녹음이 완료되었습니다. 인식을 시작합니다.\n",
      "안녕하세요 감사해요 안녕하세요 감사해요 안녕하세요 감사해요\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# initialize the recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print(\"앞으로 5초 동안 녹음합니다.\")\n",
    "    audio_data = r.record(source, duration=5)\n",
    "\n",
    "print(\"녹음이 완료되었습니다. 인식을 시작합니다.\")\n",
    "try:\n",
    "    text = r.recognize_google(audio_data, language=\"ko\")\n",
    "except:  # 다양한 예외들을 통틀어서 except 하나로 처리할 수도 있습니다.\n",
    "    print(\"음성이 인식되지 않았습니다.\")\n",
    "else:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고] 아래와 같이 ```sr.AudioFile()```을 이용해서 음성 파일을 읽어들여서 인식할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'audio_sample.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspeech_recognition\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msr\u001b[39;00m\n\u001b[1;32m      3\u001b[0m r \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mAudioFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_sample.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[1;32m      6\u001b[0m     audio \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrecord(source)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fast_lane/lib/python3.10/site-packages/speech_recognition/__init__.py:241\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis audio source is already inside a context manager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# attempt to read the file as WAV\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m \u001b[43mwave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_or_fileobject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlittle_endian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (wave\u001b[38;5;241m.\u001b[39mError, \u001b[38;5;167;01mEOFError\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fast_lane/lib/python3.10/wave.py:509\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    507\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWave_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Wave_write(f)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fast_lane/lib/python3.10/wave.py:159\u001b[0m, in \u001b[0;36mWave_read.__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_opened_the_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 159\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_opened_the_file \u001b[38;5;241m=\u001b[39m f\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# else, assume it is an open file object already\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'audio_sample.wav'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile(\"audio_sample.wav\") as source:\n",
    "    audio = r.record(source)\n",
    "\n",
    "try:\n",
    "    text = r.recognize_google(audio, language=\"ko\")\n",
    "except:\n",
    "    print(\"음성이 인식되지 않았습니다.\")\n",
    "else:\n",
    "    print(text)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23b62ad96709ddd91a685ddbb1f2ca1ce8bc759f31d2ce32b0006ee49d1f7faf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
