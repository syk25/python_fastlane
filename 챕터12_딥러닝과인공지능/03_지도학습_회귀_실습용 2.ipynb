{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a href='https://cafe.naver.com/jmhonglab'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
    "___\n",
    "<center><em>Content Copyright by HongLab, Inc.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지도학습(Supervised Learning) - 회귀(Regression)\n",
    "\n",
    "입력에 대해서 기대하는 출력이 명확한 데이터셋을 가지고 있을 경우에는 지도학습을 사용할 수 있습니다.  \n",
    "지도학습은 크게 두 가지 문제에 사용됩니다. 하나는 회귀(regression)이고 다른 하나는 분류(classification)입니다.  \n",
    "회귀는 주어진 값에 대해서 연속적인 값을 출력하는 것이고 분류는 개와 고양이를 구분하듯이 입력으로 받은 데이터를 구분짓는 것을 의미합니다.  \n",
    "여기서는 아주 간단한 직선 형태의 모델을 사용하는 **선형 회귀** 예제를 통해서 지도학습이 어떻게 이루어지는 지 알아보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공부 시간으로 점수 예상하기\n",
    "\n",
    "아래와 같은 데이터를 가지고 있을 때 3시간을 공부하면 몇 점을 받을 것으로 예상할 수 있을까?  \n",
    "\n",
    "입력(공부시간) -> 모델 -> 출력(점수)\n",
    "\n",
    "출력인 점수가 연속적인 값이기 때문에 회귀(regression) 문제입니다.\n",
    "\n",
    "|샘플|공부 시간|점수|\n",
    "|:-:|:-:|:-:|\n",
    "|학생1|1|15|\n",
    "|학생2|5|55|\n",
    "|학생3|8|60|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hours = [1.0, 5.0, 8.0] # 공부 시간\n",
    "scores = [15.0, 55.0, 60.0]\n",
    "\n",
    "plt.scatter(hours, scores, s = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 선형 회귀(linear regression)\n",
    "\n",
    "여러 개의 데이터 샘플을 모두 **적당히** 만족시킬 수 있는 직선을 어떻게 찾을 것인가?\n",
    "\n",
    "훈련(train): 모델을 데이터에 대해 최적화\n",
    "1. 초기 모델을 가정하고 난수(random numbers)로 초기화\n",
    "1. 모델에 입력 데이터(공부 시간)을 넣어서 어떤 점수를 출력하는 지 본다.\n",
    "1. 모델의 출력과 실제 데이터(점수)의 차이를 이용해서 얼마나 틀렸는지 손실(loss)을 계산한다.\n",
    "1. 현재 모델에 대한 손실의 gradient를 계산해서 손실을 줄일 수 있는 방향을 찾는다.\n",
    "1. 찾은 gradient를 이용해서 실제로 모델을 업데이트한다.\n",
    "1. 손실이 충분히 작아질 때까지 또는 미리 지정해놓은 반복횟수만큼 2단계로 돌아가서 반복한다.\n",
    "\n",
    "한 번에 여러 데이터 샘플에 대해서 gradient descent를 적용하고 싶다면 3단계와 4단계에서 여러 샘플들에 대한 loss의 평균을 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import copy # 모델 복사용\n",
    "\n",
    "torch.manual_seed(0) # 디버깅할 때 같은 결과가 나오도록\n",
    "\n",
    "# PyTorch모델 만들기\n",
    "# 선형 모델 y = ax + b 가정\n",
    "class LinearModel(torch.nn.Module): # Module 상속\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.a = torch.randn(1)\n",
    "        self.b = torch.randn(1)\n",
    "\n",
    "        self.a = torch.nn.Parameter(self.a) # Parameter로 등록\n",
    "        self.b = torch.nn.Parameter(self.b) # Parameter로 등록\n",
    "    \n",
    "    def forward(self, x): # __call__() 처럼 사용됨\n",
    "        y = self.a * x + self.b # y = ax + b\n",
    "        return y\n",
    "\n",
    "# 데이터 준비\n",
    "x_input = torch.tensor([1, 5, 8], dtype=torch.float) # 공부시간, torch.Size([3])\n",
    "y_target = torch.tensor([15, 55, 60], dtype=torch.float) # 점수, torch.Size([3])\n",
    "\n",
    "# 모델 객체 만들기 (랜덤하게 초기화)\n",
    "model = LinearModel()\n",
    "\n",
    "criterion = torch.nn.MSELoss() # Mean Squared Error (MSE) loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2) # Stochastic Gradient Descent\n",
    "\n",
    "num_epochs = 1000 # 데이터셋의 모든 샘플들에 대해 1번씩 훈련하는 것을 한 epoch라고 부릅니다.\n",
    "\n",
    "loss_history = []\n",
    "model_history = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1): # 전체 데이터에 대해서 한 번 훈련시키는 것을 epoch\n",
    "\n",
    "    optimizer.zero_grad() # 이전 훈련에서 계산했던 gradient 삭제\n",
    "\n",
    "    y_pred = model(x_input) # torch.Size([3])\n",
    "\n",
    "    # error = y_target - y_pred # torch.Size([3])\n",
    "    # loss = (error ** 2).mean() # Mean Squared Error (MSE) loss, torch.Size([])\n",
    "    loss = criterion(y_target, y_pred) # 손실(loss) 계산\n",
    "\n",
    "    loss.backward() # 모델에 대한 loss의 gradient를 계산\n",
    "\n",
    "    optimizer.step() # 모델의 parameters에 대해 gradient descent 수행\n",
    "\n",
    "    loss_history.append(loss.item())\n",
    "    model_history.append(copy.deepcopy(model)) # 용량이 클 경우 모델이나 일부 출력을 파일에 기록\n",
    "\n",
    "    if epoch % (num_epochs // 10) == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프로 결과 확인\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def visualize(x_input, y_target, loss_history, model_history, marker_size = 1):\n",
    "\n",
    "    x_input = x_input.numpy()\n",
    "    y_target = y_target.numpy()\n",
    "\n",
    "    plt.figure(figsize=(24, 6))\n",
    "\n",
    "    plt.subplot(141)\n",
    "\n",
    "    plt.scatter(x_input, y_target, s = marker_size) # 모든 데이터 샘플 그리기\n",
    "\n",
    "    # 훈련 마지막 모델의 출력 그리기\n",
    "    x = np.linspace(x_input.min(), x_input.max(), 10)\n",
    "    y = model_history[-1](torch.tensor(x)).detach().numpy() \n",
    "    plt.plot(x, y, c=\"red\")\n",
    "    #[참고] tensor.detach().numpy(): 훈련에 필요한 정보들은 빼고 순수 값만 넘파이로 변환\n",
    "\n",
    "    plt.subplot(142)\n",
    "\n",
    "    num_steps = len(loss_history) // 10\n",
    "    plt.scatter(x_input, y_target, s = marker_size) # 샘플 그리기\n",
    "    colors = plt.cm.rainbow(np.linspace(0,1,10))\n",
    "    for i in range(0, len(model_history), num_steps):\n",
    "        y = model_history[i](torch.tensor(x)).detach().numpy()\n",
    "        plt.plot(x, y, c=colors[i//num_steps])\n",
    "\n",
    "    plt.subplot(143)\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(loss_history)\n",
    "\n",
    "    plt.subplot(144)\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Log loss\")\n",
    "    plt.plot([math.log(l) for l in loss_history])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "visualize(x_input, y_target, loss_history, model_history, marker_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model_history[-1]\n",
    "\n",
    "y_pred = trained_model(torch.tensor([3.0]))\n",
    "\n",
    "print(y_pred.item()) # 32.268489837646484"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 어떠한 손실 함수를 사용할 것인가?\n",
    "\n",
    "\n",
    "[참고] loss는 분야에 따라 cost, energy 등 다른 이름으로 불리기도 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "error = np.linspace(-1, 1, 100)\n",
    "loss1 = error\n",
    "loss2 = abs(error)\n",
    "loss3 = 0.5 * error ** 2 # 앞에 0.5 붙이는 경우도 있고 붙이지 않는 경우도 있다.\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Error Error\")\n",
    "plt.plot(error, loss1)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Abs Error\")\n",
    "plt.plot(error, loss2)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Squared Error\")\n",
    "plt.plot(error, loss3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [실습] [다이아몬드](https://www.kaggle.com/datasets/shivam2503/diamonds?resource=download) 데이터셋 \n",
    "\n",
    "2.5 캐럿 다이아몬드의 예상 가격은?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 읽어들이기\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('diamonds.csv')\n",
    "\n",
    "df.plot.scatter(x=\"carat\", y=\"price\", s=0.1, figsize=(9, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x$는 carat(다이아몬드의 무게), $y$는 price(가격)에 대해 선형 회귀를 수행  \n",
    "Learning rate와 반복 회수를 스스로 결정해서 여러가지로 테스트 해보기  \n",
    "이때, learning rate가 너무 크면 수치적으로 불안정해져서 문제 발생    \n",
    "반복 횟수가 너무 적으면 결과가 정확하지 않음  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import copy # 모델 복사용\n",
    "\n",
    "torch.manual_seed(0) # 디버깅할 때 같은 결과가 나오도록\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [실습] 2차 곡선 맞춤 (Curve Fitting)\n",
    "\n",
    "모델을 $y = ax^2 + bx + c$로 바꿔보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [참고] [scikit-learn](https://scikit-learn.org/stable/)의 선형회귀\n",
    "\n",
    "데이터 사이언스에서는 scikit-learn을 많이 사용합니다. scikit-learn에서 선형회귀 하는 코드이니 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('diamonds.csv')\n",
    "\n",
    "x_input = df[\"carat\"].to_numpy() # input\n",
    "y_target = df[\"price\"].to_numpy() # output\n",
    "\n",
    "x_input = np.expand_dims(x_input, axis=1)\n",
    "y_target = np.expand_dims(y_target, axis=1)\n",
    "\n",
    "regr = LinearRegression()\n",
    "regr.fit(x_input, y_target)\n",
    "\n",
    "y_pred = regr.predict(x_input)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x_input.squeeze(), y_target.squeeze(), s = 0.1) # 샘플 그리기\n",
    "plt.plot(x_input.squeeze(), y_pred.squeeze(), c=\"red\")\n",
    "\n",
    "print(regr.predict([[2.5]])) # [[17134.70346488]]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d020ba169b33221ab358611b87de83a49ae84c7ba35bfa72ae9e245c465f61e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('py10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
